# Eval Registry
# Reference: https://github.com/openai/evals/blob/main/docs/eval-templates.md
#
# Format inspired by OpenAI Evals YAML registry
# Each eval defines:
# - id: Unique identifier
# - name: Human-readable name
# - description: What this eval measures
# - criteria: List of evaluation criteria with weights

evals:
  - id: skill-md-validation
    name: SKILL.md Metadata Validation
    description: |
      Validates that a skill has proper SKILL.md structure with
      frontmatter, name, description, and location fields.
    metrics:
      - has-skill-md
      - has-frontmatter
      - has-name
      - has-description
      - has-location
      - has-available-skills
  
  - id: skill-trigger-validation
    name: Trigger Pattern Validation
    description: |
      Ensures skill triggers are properly defined with valid regex patterns.
    metrics:
      - has-triggers-section
      - has-valid-patterns
      - non-empty-triggers
  
  - id: code-quality
    name: Code Quality Assessment
    description: |
      Evaluates the quality of skill implementation including
      test coverage and modular structure.
    metrics:
      - has-implementation
      - has-tests
      - has-readme
      - modular-structure
  
  - id: compatibility
    name: Platform Compatibility
    description: |
      Checks that the skill is compatible with agent platforms
      like Claude Code, OpenCode, and OpenClaw.
    metrics:
      - has-agent-config
      - has-commands
      - has-hooks
      - has-scripts
  
  - id: documentation
    name: Documentation Quality
    description: |
      Assesses the completeness of skill documentation.
    metrics:
      - has-usage-examples
      - has-requirements
      - has-known-issues
